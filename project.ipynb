{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "version": "0.3.2",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/dipeshjn/TwitterBot/blob/master/project.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "mwkDrf1dXJZg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install python-twitter\n",
        "!pip install paralleldots\n",
        "!pip install tweepy\n",
        "!pip install nltk"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QMlq6SclYOIz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import twitter\n",
        "api = twitter.Api(consumer_key = '',\n",
        "                  consumer_secret = '',\n",
        "                  access_token_key = '',\n",
        "                  access_token_secret = '')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7QPwYcUZw5Kn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "API_KEY = ''\n",
        "API_SECRET = ''\n",
        "ACCESS_TOKEN = ''\n",
        "ACCESS_TOKEN_SECRET = ''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M74SZxN4FQ_K",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_status(query):\n",
        "  import pprint\n",
        "  hasgtag = \"#\" + query\n",
        "  tweets = api.GetSearch(hasgtag , count=10 , return_json=True)\n",
        "  pp = pprint.PrettyPrinter(indent=2)\n",
        "  pp.pprint(tweets)\n",
        "\n",
        "def get_tweets(query):\n",
        "  hashtag = \"#\" + query\n",
        "  tweets = api.GetSearch(hashtag , count=10 , return_json=True)\n",
        "  return tweets\n",
        "\n",
        "def get_analyse(query):\n",
        "  tweets = get_tweets(query)\n",
        "  import paralleldots\n",
        "  api_key = \"KwHJMmzba9qn0WBerA5fMsNSEddzmCHECUNdHW8Rldc\"\n",
        "  paralleldots.set_api_key(api_key)\n",
        "  my_list = []\n",
        "  for each_tweet in tweets['statuses']:\n",
        "    analyze = paralleldots.sentiment(each_tweet['text'])\n",
        "    my_list.append(analyze)\n",
        "  return my_list\n",
        "  \n",
        "def get_num_followers(query):\n",
        "  tweets = get_tweets(query)\n",
        "  import json\n",
        "  num_followers=0\n",
        "  print json.dumps(tweets)\n",
        "  for each_tweet in tweets['statuses']:\n",
        "    print each_tweet['user']['followers_count']\n",
        "    num_followers+=each_tweet['user']['followers_count']\n",
        "  return num_followers\n",
        "  \n",
        "def get_sentiment(query):\n",
        "  my_list = get_analyse(query)\n",
        "  import json\n",
        "  nutweet=0\n",
        "  ntweet=0\n",
        "  ptweet=0\n",
        "  #print(json.dumps(my_list))\n",
        "  for i in my_list:\n",
        "    if (i['sentiment'] == \"neutral\"):\n",
        "      nutweet+=1\n",
        "    elif (i['sentiment'] == \"negative\"):\n",
        "      ntweet+=1\n",
        "    else:\n",
        "      ptweet+=1\n",
        "  print \"positive tweets are:%s\"%ptweet\n",
        "  print \"neutral tweets are:%s\"%nutweet\n",
        "  print \"negative tweets are:%s\"%ntweet\n",
        "    \n",
        "def get_ln_tym_loc(query):\n",
        "  import pandas as pd\n",
        "  hashtag = \"#\" + query\n",
        "  tweets = get_tweets(query)\n",
        "  for each_tweet in tweets['statuses']:\n",
        "    my_dict={}\n",
        "    my_dict['location']=each_tweet['user']['location']\n",
        "    my_dict['time_zone']=each_tweet['user']['time_zone']\n",
        "    my_dict['lang'] = each_tweet['user']['lang']\n",
        "    print my_dict\n",
        "  public_tweets = api.GetSearch(hashtag, count=10)\n",
        "  data = pd.DataFrame()\n",
        "  data['location']=[tweets.user.location for tweets in public_tweets]\n",
        "  data['lang']=[tweets.user.lang for tweets in public_tweets]\n",
        "  data['time_zone']=[tweets.user.time_zone for tweets in public_tweets]\n",
        "  print(\"\\n counter for various locations:\")\n",
        "  print data['location'].value_counts()\n",
        "  print(\"\\n counter for various languages:\")\n",
        "  print data['lang'].value_counts()\n",
        "  print(\"\\n counter for various time_zones:\")\n",
        "  print data['time_zone'].value_counts()\n",
        "  \n",
        "def get_compare():\n",
        "  import tweepy\n",
        "  import re\n",
        "  import json\n",
        "  auth = tweepy.OAuthHandler(API_KEY, API_SECRET)\n",
        "  auth.set_access_token(ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n",
        "  api = tweepy.API(auth)\n",
        "\n",
        "  #####Narendra Modi \n",
        "\n",
        "  new_tweets1 = api.user_timeline(screen_name ='@narendramodi',count=200, tweet_mode=\"extended\")\n",
        "  #tweets1 = [[tweet.full_text] for tweet in new_tweets1]\n",
        "  #print json.dumps(tweets1)\n",
        "  my_text1 = []\n",
        "  for tweet in new_tweets1:\n",
        "    text1 = tweet.full_text\n",
        "    my_text1.append(text1)\n",
        "    str1 = ''.join(my_text1)\n",
        "    result1 = re.sub(r\"http\\S+\", \"\", str1)\n",
        "    #print(result1)\n",
        "\n",
        "  patterns1 = ['\\sUSA\\s','\\sUS\\s','\\sAmerica\\s','\\sUnited states of America\\s']\n",
        "  #str1.count('US')\n",
        "  count1=0\n",
        "  print(\"Check if PM Modi has mentioned 'USA','US','America' OR 'United States of America' in his last 200 tweets:\")\n",
        "  for pattern in patterns1:\n",
        "    #print('looking for \"%s\" in \"%s\" ->'%(pattern,str1))\n",
        "    if re.search(pattern,result1):\n",
        "      print('\"%s\" : found'%(pattern))\n",
        "      count1+=1\n",
        "    else:\n",
        "      print('\"%s\" : not found'%(pattern))\n",
        "  \n",
        "  print(\"counted are:%s\"%count1)  \n",
        "\n",
        "  #####DonaldTrump\n",
        "\n",
        "  new_tweets2 = api.user_timeline(screen_name ='@realDonaldTrump',count=200, tweet_mode=\"extended\")\n",
        "  #tweets2 = [[tweet.full_text] for tweet in new_tweets2]\n",
        "  #print json.dumps(tweets2)\n",
        "  my_text2 = []\n",
        "  for tweet in new_tweets2:\n",
        "    text2 = tweet.full_text\n",
        "    my_text2.append(text2)\n",
        "    str2 = ''.join(my_text2)\n",
        "    result2 = re.sub(r\"http\\S+\", \"\", str2)\n",
        "    #print(result2)\n",
        "\n",
        "  patterns2 = ['\\sindia\\s','\\sIndia\\s']\n",
        "  #str2.count('India')\n",
        "  count2=0\n",
        "  print(\"Check if Donald Trump has mentioned 'india' OR 'India' in his last 200 tweets:\")\n",
        "  for pattern in patterns2:\n",
        "    #print('looking for \"%s\" in \"%s\" ->'%(pattern,str2))\n",
        "    if re.search(pattern,str2):\n",
        "      print('\"%s\" : found'%(pattern))\n",
        "      count2+=1\n",
        "    else:\n",
        "      print('\"%s\" : not found'%(pattern))\n",
        "  \n",
        "  print(\"counted are:%s\"%count2) \n",
        "  \n",
        "def get_top_words():\n",
        "  import nltk\n",
        "  from nltk.corpus import stopwords\n",
        "  from nltk.tokenize import word_tokenize\n",
        "  nltk.download('stopwords') \n",
        "  nltk.download('punkt')\n",
        "  stop_words = set(stopwords.words('english'))\n",
        "  import tweepy\n",
        "  import re\n",
        "  auth = tweepy.OAuthHandler(API_KEY, API_SECRET)\n",
        "  auth.set_access_token(ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n",
        "  api = tweepy.API(auth)\n",
        "  new_tweets = api.user_timeline(screen_name ='@narendramodi',count=200, tweet_mode=\"extended\")\n",
        "  print(\"--------------\")\n",
        "  my_text = []\n",
        "  for tweet in new_tweets:\n",
        "    text = tweet.full_text\n",
        "    my_text.append(text)\n",
        "  str1 = ''.join(my_text)\n",
        "  result = re.sub(r'[^\\w]', ' ', str1)\n",
        "  result1 = re.sub(r\"http\\S+\", \"\", result)\n",
        "  \n",
        "  word_tokens = word_tokenize(result1)\n",
        "\n",
        "  filtered_sentence = [w for w in word_tokens if not w in stop_words]\n",
        "  filtered_sentence = []\n",
        "  for w in word_tokens:\n",
        "    if w not in stop_words:\n",
        "      filtered_sentence.append(w)\n",
        "  str2 = ''.join(filtered_sentence)\n",
        "\n",
        "  import pandas as pd\n",
        "  df = pd.DataFrame({'col':filtered_sentence})\n",
        "  print(\"\\nTop 10 words used by PM Modi are as follows:\")\n",
        "  top = df.col.str.split(expand=True).stack().value_counts()[1:11,]\n",
        "  print(top)\n",
        "  \n",
        "def get_status_update(query):\n",
        "  import tweepy\n",
        "  auth = tweepy.OAuthHandler(API_KEY, API_SECRET)\n",
        "  auth.set_access_token(ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n",
        "  api = tweepy.API(auth)\n",
        "  api.update_status(query)\n",
        "    \n",
        "def main():\n",
        "  while(True):\n",
        "    user_choice = input(\"1. Tweet Retreival and their status class.\\n\"\n",
        "                        \"2. Count the total no. of followers of people Tweeting using a certain Hashtag.\\n\"\n",
        "                        \"3. Determine the location, Timezone and Language of people Tweeting using a certain Hashtag.\\n\"\n",
        "                        \"4. Numbers of times Modi has referred to US in the past 200 Tweets compared to how many times Trump has mentioned India.\\n\"\n",
        "                        \"5. Determine the Sentiment of people Tweeting using a certain Hashtag.\\n\"\n",
        "                        \"6. Top 10 words used by PM Modi on Twitter.\\n\"\n",
        "                        \"7. Tweet a message from your account.\\n\"\n",
        "                        \"8. Exit.\\n\")\n",
        "    if user_choice==1:\n",
        "      user_input = raw_input(\"Enter the Hashtag:\")\n",
        "      get_status(user_input)\n",
        "    elif user_choice==2:\n",
        "      user_input = raw_input(\"Enter the Hashtag:\")\n",
        "      print \"\\n\\n Max. no. of people who might have seen this Hashatg: %s\" %(get_num_followers(user_input))\n",
        "    elif user_choice==3:\n",
        "      user_input = raw_input(\"Enter the Hashtag:\")\n",
        "      get_ln_tym_loc(user_input)\n",
        "    elif user_choice==4:\n",
        "      get_compare()\n",
        "    elif user_choice==5:\n",
        "      user_input = raw_input(\"Enter the Hashtag:\")\n",
        "      get_sentiment(user_input)\n",
        "    elif user_choice==6:\n",
        "      get_top_words()\n",
        "    elif user_choice==7:\n",
        "      user_input = raw_input(\"Enter the Status:\")\n",
        "      get_status_update(user_input) \n",
        "    elif user_choice==8:\n",
        "        break\n",
        "    else:print(\"i didn't get that, plz try again.\\n\")\n",
        "          \n",
        "main()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mARoUsQhR2Ln",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}