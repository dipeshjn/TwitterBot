{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "version": "0.3.2",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/dipeshjn/TwitterBot/blob/master/acadview_project2.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "mwkDrf1dXJZg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 739
        },
        "outputId": "0574eb94-8c83-4f76-a018-c6b917556f84"
      },
      "cell_type": "code",
      "source": [
        "!pip install python-twitter\n",
        "!pip install paralleldots\n",
        "!pip install tweepy\n",
        "!pip install nltk"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting python-twitter\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/36/533f370b1018443cf25734273833611ff445adae89122a36df02362a7468/python_twitter-3.4.1-py2.py3-none-any.whl (73kB)\n",
            "\u001b[K    100% |████████████████████████████████| 81kB 2.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python2.7/dist-packages (from python-twitter) (0.16.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python2.7/dist-packages (from python-twitter) (0.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python2.7/dist-packages (from python-twitter) (2.18.4)\n",
            "Requirement already satisfied: oauthlib>=0.6.2 in /usr/local/lib/python2.7/dist-packages (from requests-oauthlib->python-twitter) (2.0.7)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python2.7/dist-packages (from requests->python-twitter) (2.6)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python2.7/dist-packages (from requests->python-twitter) (1.22)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python2.7/dist-packages (from requests->python-twitter) (2018.4.16)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python2.7/dist-packages (from requests->python-twitter) (3.0.4)\n",
            "Installing collected packages: python-twitter\n",
            "Successfully installed python-twitter-3.4.1\n",
            "Collecting paralleldots\n",
            "  Downloading https://files.pythonhosted.org/packages/9d/06/92b7313f0d0cbae25c0963ff2b2872a10c7684f600bf50936828eb06c3db/ParallelDots-3.2.5-py2.py3-none-any.whl\n",
            "Requirement already satisfied: requests in /usr/local/lib/python2.7/dist-packages (from paralleldots) (2.18.4)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python2.7/dist-packages (from requests->paralleldots) (2.6)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python2.7/dist-packages (from requests->paralleldots) (1.22)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python2.7/dist-packages (from requests->paralleldots) (2018.4.16)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python2.7/dist-packages (from requests->paralleldots) (3.0.4)\n",
            "Installing collected packages: paralleldots\n",
            "Successfully installed paralleldots-3.2.5\n",
            "Collecting tweepy\n",
            "  Downloading https://files.pythonhosted.org/packages/05/f1/2e8c7b202dd04117a378ac0c55cc7dafa80280ebd7f692f1fa8f27fd6288/tweepy-3.6.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python2.7/dist-packages (from tweepy) (1.11.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python2.7/dist-packages (from tweepy) (0.8.0)\n",
            "Collecting PySocks>=1.5.7 (from tweepy)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/53/12/6bf1d764f128636cef7408e8156b7235b150ea31650d0260969215bb8e7d/PySocks-1.6.8.tar.gz (283kB)\n",
            "\u001b[K    100% |████████████████████████████████| 286kB 7.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.11.1 in /usr/local/lib/python2.7/dist-packages (from tweepy) (2.18.4)\n",
            "Requirement already satisfied: oauthlib>=0.6.2 in /usr/local/lib/python2.7/dist-packages (from requests-oauthlib>=0.7.0->tweepy) (2.0.7)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python2.7/dist-packages (from requests>=2.11.1->tweepy) (2.6)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python2.7/dist-packages (from requests>=2.11.1->tweepy) (1.22)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python2.7/dist-packages (from requests>=2.11.1->tweepy) (2018.4.16)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python2.7/dist-packages (from requests>=2.11.1->tweepy) (3.0.4)\n",
            "Building wheels for collected packages: PySocks\n",
            "  Running setup.py bdist_wheel for PySocks ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/22/5c/b5/12e0dfdfa85bea67b23628b6425fae715c687e947a45ee3df9\n",
            "Successfully built PySocks\n",
            "Installing collected packages: PySocks, tweepy\n",
            "Successfully installed PySocks-1.6.8 tweepy-3.6.0\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python2.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python2.7/dist-packages (from nltk) (1.11.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QMlq6SclYOIz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import twitter\n",
        "api = twitter.Api(consumer_key = '',\n",
        "                  consumer_secret = '',\n",
        "                  access_token_key = '',\n",
        "                  access_token_secret = '')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7QPwYcUZw5Kn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "API_KEY = ''\n",
        "API_SECRET = ''\n",
        "ACCESS_TOKEN = ''\n",
        "ACCESS_TOKEN_SECRET = ''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M74SZxN4FQ_K",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_status(query):\n",
        "  import pprint\n",
        "  hasgtag = \"#\" + query\n",
        "  tweets = api.GetSearch(hasgtag , count=10 , return_json=True)\n",
        "  pp = pprint.PrettyPrinter(indent=2)\n",
        "  pp.pprint(tweets)\n",
        "\n",
        "def get_tweets(query):\n",
        "  hashtag = \"#\" + query\n",
        "  tweets = api.GetSearch(hashtag , count=10 , return_json=True)\n",
        "  return tweets\n",
        "\n",
        "def get_analyse(query):\n",
        "  tweets = get_tweets(query)\n",
        "  import paralleldots\n",
        "  api_key = \"KwHJMmzba9qn0WBerA5fMsNSEddzmCHECUNdHW8Rldc\"\n",
        "  paralleldots.set_api_key(api_key)\n",
        "  my_list = []\n",
        "  for each_tweet in tweets['statuses']:\n",
        "    analyze = paralleldots.sentiment(each_tweet['text'])\n",
        "    my_list.append(analyze)\n",
        "  return my_list\n",
        "  \n",
        "def get_num_followers(query):\n",
        "  tweets = get_tweets(query)\n",
        "  import json\n",
        "  num_followers=0\n",
        "  print json.dumps(tweets)\n",
        "  for each_tweet in tweets['statuses']:\n",
        "    my_dict={}\n",
        "    my_dict['screen_name']=each_tweet['user']['screen_name']\n",
        "    my_dict['followers_count']=each_tweet['user']['followers_count']\n",
        "    print my_dict\n",
        "    #print(each_tweet['user']['screen_name'] & each_tweet['user']['followers_count'])\n",
        "    num_followers+=each_tweet['user']['followers_count']\n",
        "  return num_followers\n",
        "  \n",
        "def get_sentiment(query):\n",
        "  my_list = get_analyse(query)\n",
        "  import json\n",
        "  nutweet=0\n",
        "  ntweet=0\n",
        "  ptweet=0\n",
        "  #print(json.dumps(my_list))\n",
        "  for i in my_list:\n",
        "    if (i['sentiment'] == \"neutral\"):\n",
        "      nutweet+=1\n",
        "    elif (i['sentiment'] == \"negative\"):\n",
        "      ntweet+=1\n",
        "    else:\n",
        "      ptweet+=1\n",
        "  print \"positive tweets are:%s\"%ptweet\n",
        "  print \"neutral tweets are:%s\"%nutweet\n",
        "  print \"negative tweets are:%s\"%ntweet\n",
        "    \n",
        "def get_ln_tym_loc(query):\n",
        "  import pandas as pd\n",
        "  import numpy as np\n",
        "  hashtag = \"#\" + query\n",
        "  tweets = get_tweets(query)\n",
        "  for each_tweet in tweets['statuses']:\n",
        "    my_dict={}\n",
        "    my_dict['location']=each_tweet['user']['location']\n",
        "    my_dict['time_zone']=each_tweet['user']['time_zone']\n",
        "    my_dict['lang'] = each_tweet['user']['lang']\n",
        "    print my_dict\n",
        "  public_tweets = api.GetSearch(hashtag, count=10)\n",
        "  data = pd.DataFrame()\n",
        "  data['location']=[tweets.user.location for tweets in public_tweets]\n",
        "  data['lang']=[tweets.user.lang for tweets in public_tweets]\n",
        "  data['time_zone']=[tweets.user.time_zone for tweets in public_tweets]\n",
        "  print(\"\\n counter for various locations:\")\n",
        "  print data['location'].value_counts()\n",
        "  print(\"\\n counter for various languages:\")\n",
        "  print data['lang'].value_counts()\n",
        "  print(\"\\n counter for various time_zones:\")\n",
        "  print data['time_zone'].value_counts()\n",
        "  \n",
        "def get_compare():\n",
        "  import tweepy\n",
        "  import re\n",
        "  import json\n",
        "  auth = tweepy.OAuthHandler(API_KEY, API_SECRET)\n",
        "  auth.set_access_token(ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n",
        "  api = tweepy.API(auth)\n",
        "\n",
        "  #####Narendra Modi \n",
        "\n",
        "  new_tweets1 = api.user_timeline(screen_name ='@narendramodi',count=200, tweet_mode=\"extended\")\n",
        "  #tweets1 = [[tweet.full_text] for tweet in new_tweets1]\n",
        "  #print json.dumps(tweets1)\n",
        "  my_text1 = []\n",
        "  for tweet in new_tweets1:\n",
        "    text1 = tweet.full_text\n",
        "    my_text1.append(text1)\n",
        "    str1 = ''.join(my_text1)\n",
        "    result1 = re.sub(r\"http\\S+\", \"\", str1)\n",
        "    #print(result1)\n",
        "\n",
        "  patterns1 = ['\\sUSA\\s','\\sUS\\s','\\sAmerica\\s','\\sUnited states of America\\s']\n",
        "  #str1.count('US')\n",
        "  count1=0\n",
        "  print(\"Check if PM Modi has mentioned 'USA','US','America' OR 'United States of America' in his last 200 tweets:\")\n",
        "  for pattern in patterns1:\n",
        "    #print('looking for \"%s\" in \"%s\" ->'%(pattern,str1))\n",
        "    if re.search(pattern,result1):\n",
        "      print('\"%s\" : found'%(pattern))\n",
        "      count1+=1\n",
        "    print('\\nno. of times %s found : %s'%(pattern,count1))  \n",
        "\n",
        "  #####DonaldTrump\n",
        "\n",
        "  new_tweets2 = api.user_timeline(screen_name ='@realDonaldTrump',count=200, tweet_mode=\"extended\")\n",
        "  #tweets2 = [[tweet.full_text] for tweet in new_tweets2]\n",
        "  #print json.dumps(tweets2)\n",
        "  my_text2 = []\n",
        "  for tweet in new_tweets2:\n",
        "    text2 = tweet.full_text\n",
        "    my_text2.append(text2)\n",
        "    str2 = ''.join(my_text2)\n",
        "    result2 = re.sub(r\"http\\S+\", \"\", str2)\n",
        "    #print(result2)\n",
        "\n",
        "  patterns2 = ['\\sindia\\s','\\sIndia\\s']\n",
        "  #str2.count('India')\n",
        "  count2=0\n",
        "  print(\"\\nCheck if Donald Trump has mentioned 'india' OR 'India' in his last 200 tweets:\")\n",
        "  for pattern in patterns2:\n",
        "    #print('looking for \"%s\" in \"%s\" ->'%(pattern,str2))\n",
        "    if re.search(pattern,str2):\n",
        "      print('\"%s\" : found'%(pattern))\n",
        "      count2+=1\n",
        "    print('\\nno. of times %s found : %s'%(pattern,count2))\n",
        "  \n",
        "def get_top_words():\n",
        "  import nltk\n",
        "  from nltk.corpus import stopwords\n",
        "  from nltk.tokenize import word_tokenize\n",
        "  nltk.download('stopwords') \n",
        "  nltk.download('punkt')\n",
        "  stop_words = set(stopwords.words('english'))\n",
        "  import tweepy\n",
        "  import re\n",
        "  auth = tweepy.OAuthHandler(API_KEY, API_SECRET)\n",
        "  auth.set_access_token(ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n",
        "  api = tweepy.API(auth)\n",
        "  new_tweets = api.user_timeline(screen_name ='@narendramodi',count=200, tweet_mode=\"extended\")\n",
        "  print(\"--------------\")\n",
        "  my_text = []\n",
        "  for tweet in new_tweets:\n",
        "    text = tweet.full_text\n",
        "    my_text.append(text)\n",
        "  str1 = ''.join(my_text)\n",
        "  result = re.sub(r'[^\\w]', ' ', str1)\n",
        "  result1 = re.sub(r\"http\\S+\", \"\", result)\n",
        "  \n",
        "  word_tokens = word_tokenize(result1)\n",
        "\n",
        "  filtered_sentence = [w for w in word_tokens if not w in stop_words]\n",
        "  filtered_sentence = []\n",
        "  for w in word_tokens:\n",
        "    if w not in stop_words:\n",
        "      filtered_sentence.append(w)\n",
        "  str2 = ''.join(filtered_sentence)\n",
        "\n",
        "  import pandas as pd\n",
        "  df = pd.DataFrame({'col':filtered_sentence})\n",
        "  print(\"\\nTop 10 words used by PM Modi are as follows:\")\n",
        "  top = df.col.str.split(expand=True).stack().value_counts()[1:11,]\n",
        "  print(top)\n",
        "  \n",
        "def get_status_update(query):\n",
        "  import tweepy\n",
        "  auth = tweepy.OAuthHandler(API_KEY, API_SECRET)\n",
        "  auth.set_access_token(ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n",
        "  api = tweepy.API(auth)\n",
        "  api.update_status(query)\n",
        "    \n",
        "def main():\n",
        "  while(True):\n",
        "    user_choice = input(\"1. Tweet Retreival and their status class.\\n\"\n",
        "                        \"2. Count the total no. of followers of people Tweeting using a certain Hashtag.\\n\"\n",
        "                        \"3. Determine the location, Timezone and Language of people Tweeting using a certain Hashtag.\\n\"\n",
        "                        \"4. Numbers of times Modi has referred to US in the past 200 Tweets compared to how many times Trump has mentioned India.\\n\"\n",
        "                        \"5. Determine the Sentiment of people Tweeting using a certain Hashtag.\\n\"\n",
        "                        \"6. Top 10 words used by PM Modi on Twitter.\\n\"\n",
        "                        \"7. Tweet a message from your account.\\n\"\n",
        "                        \"8. Exit.\\n\")\n",
        "    if user_choice==1:\n",
        "      user_input = raw_input(\"Enter the Hashtag:\")\n",
        "      get_status(user_input)\n",
        "    elif user_choice==2:\n",
        "      user_input = raw_input(\"Enter the Hashtag:\")\n",
        "      print \"\\n\\n Max. no. of people who might have seen this Hashatg: %s\" %(get_num_followers(user_input))\n",
        "    elif user_choice==3:\n",
        "      user_input = raw_input(\"Enter the Hashtag:\")\n",
        "      get_ln_tym_loc(user_input)\n",
        "    elif user_choice==4:\n",
        "      get_compare()\n",
        "    elif user_choice==5:\n",
        "      user_input = raw_input(\"Enter the Hashtag:\")\n",
        "      get_sentiment(user_input)\n",
        "    elif user_choice==6:\n",
        "      get_top_words()\n",
        "    elif user_choice==7:\n",
        "      user_input = raw_input(\"Enter the Status:\")\n",
        "      get_status_update(user_input) \n",
        "    elif user_choice==8:\n",
        "        break\n",
        "    else:print(\"i didn't get that, plz try again.\\n\")\n",
        "          \n",
        "main()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zsJ_c4VNMrs9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}